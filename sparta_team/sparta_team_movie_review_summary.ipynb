{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7465e777-4bab-4b2e-9b18-b8e4ca150fbf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7465e777-4bab-4b2e-9b18-b8e4ca150fbf",
        "outputId": "bae0e8b9-49f8-4dca-f129-2e87a4671ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the dataset: (117040, 8)\n",
            "Columns in the dataset: Index(['reviewId', 'userName', 'content', 'score', 'thumbsUpCount',\n",
            "       'reviewCreatedVersion', 'at', 'appVersion'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#데이터셋 불러오기\n",
        "df = pd.read_csv(\"netflix_reviews.csv\")\n",
        "\n",
        "# 데이터셋 크기와 열 정보 출력|\n",
        "print(f\"Shape of the dataset: {df.shape}\")\n",
        "print(f\"Columns in the dataset: {df.columns}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "af75d52e-348a-4caf-ab78-72c2a1d1a1b5",
      "metadata": {
        "id": "af75d52e-348a-4caf-ab78-72c2a1d1a1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea6d2af-e1c9-47e9-eb4c-4871869d2696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, float):\n",
        "        return \"\"\n",
        "    text = text.lower()  # 대문자를 소문자로\n",
        "    text = text.strip()  # 띄어쓰기 제외하고 빈 칸 제거\n",
        "    pattern = r'[^a-zA-Z가-힣]'\n",
        "    text = re.sub(r'[^a-zA-Z\\s.!?,]', '', text)  # 알파벳, 공백, 그리고 일부 구두점만 유지\n",
        "    return text\n",
        "\n",
        "# 불필요한 열 제거\n",
        "df = df[['content', 'score']]\n",
        "\n",
        "# 리뷰 텍스트 정제\n",
        "df['content'] = df['content'].apply(preprocess_text)\n",
        "\n",
        "# 불용어 제거\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['content'] = df['content'].apply(remove_stopwords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d7a41afa-5ff4-4e8d-b9f6-bd73c4dcfbe8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "d7a41afa-5ff4-4e8d-b9f6-bd73c4dcfbe8",
        "outputId": "e7bd65ac-c8c4-47f9-c932-053786f396be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 리뷰 점수 분포 확인\n",
        "sns.countplot(x='score', data=df)\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Scores')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import nltk\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 데이터 준비 (리뷰와 평점 컬럼을 추출)\n",
        "reviews = df['content']\n",
        "ratings = df['score']\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할 (train_test_split 사용)\n",
        "train_reviews, test_reviews, train_ratings, test_ratings = train_test_split(reviews, ratings, test_size=0.3, random_state=42)\n",
        "\n",
        "# 인덱스 초기화 (데이터 프레임 인덱스 리셋)\n",
        "train_reviews.reset_index(drop=True, inplace=True)\n",
        "train_ratings.reset_index(drop=True, inplace=True)\n",
        "test_reviews.reset_index(drop=True, inplace=True)\n",
        "test_ratings.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 단어 사전 구축 함수 정의 (리뷰 텍스트를 토큰화하고 사전 생성)\n",
        "def build_vocab(reviews):\n",
        "    tokenized_reviews = [word_tokenize(review) for review in reviews]\n",
        "    vocab = build_vocab_from_iterator(tokenized_reviews, specials=[\"<pad>\", \"<unk>\"])\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])  # 알 수 없는 단어 처리\n",
        "    return vocab\n",
        "\n",
        "# 데이터셋 클래스 정의 (데이터셋을 커스텀하여 사용하기 위해 클래스 정의)\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, reviews, ratings, text_pipeline, label_pipeline):\n",
        "        self.reviews = reviews\n",
        "        self.ratings = ratings\n",
        "        self.text_pipeline = text_pipeline\n",
        "        self.label_pipeline = label_pipeline\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        review = self.text_pipeline(self.reviews[idx])\n",
        "        rating = self.label_pipeline(self.ratings[idx])\n",
        "        return review, rating\n",
        "\n",
        "# 패딩과 텐서 변환을 위한 collate 함수 정의\n",
        "def collate_fn(batch):\n",
        "    reviews, ratings = zip(*batch)  # 배치에서 리뷰와 레이팅 분리\n",
        "    reviews_padded = pad_sequence(reviews, batch_first=True)  # 리뷰를 패딩\n",
        "    ratings_tensor = torch.tensor(ratings, dtype=torch.long)  # 레이팅을 텐서로 변환\n",
        "    return reviews_padded, ratings_tensor  # 패딩된 리뷰와 레이팅 반환\n",
        "\n",
        "# 단어 사전 생성 (훈련 데이터 리뷰를 기반으로 어휘 사전 구축)\n",
        "vocab = build_vocab(train_reviews)\n",
        "\n",
        "# 텍스트 파이프라인 정의 (텍스트를 토큰화하고 텐서로 변환)\n",
        "def text_pipeline(text):\n",
        "    tokenized = word_tokenize(text)  # 토큰화\n",
        "    return torch.tensor([vocab[token] for token in tokenized], dtype=torch.long)\n",
        "\n",
        "# 레이블 파이프라인 클래스 정의 (평점을 수치화하여 모델에 입력)\n",
        "class LabelPipeline:\n",
        "    def __init__(self):\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, labels):\n",
        "        self.label_encoder.fit(labels)\n",
        "\n",
        "    def __call__(self, label):\n",
        "        return self.label_encoder.transform([label])[0]\n",
        "\n",
        "# 레이블 파이프라인 초기화 및 학습\n",
        "label_pipeline = LabelPipeline()\n",
        "label_pipeline.fit(df['score'].values)\n",
        "\n",
        "# 데이터셋 정의 (훈련 및 테스트 데이터셋 구성)\n",
        "train_dataset = ReviewDataset(train_reviews, train_ratings, text_pipeline, label_pipeline)\n",
        "test_dataset = ReviewDataset(test_reviews, test_ratings, text_pipeline, label_pipeline)\n",
        "\n",
        "# 데이터 로더 정의 (DataLoader를 통해 배치로 데이터를 로딩)\n",
        "BATCH_SIZE = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "# 모델 정의 (LSTM 모델 구조를 설정하여 시퀀스 처리 수행)\n",
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=True, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Sequential(\n",
        "    nn.Linear(hidden_dim, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(128, output_dim)\n",
        ")\n",
        "\n",
        "  # 순전파 정의 (입력 텍스트를 임베딩하고 LSTM과 FC 계층에 통과)\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    output, (hidden, cell) = self.lstm(embedded)  # 배치 사이즈에 맞게 차원 추가\n",
        "    return self.fc(hidden[-1].view(hidden.size(1), -1))\n",
        "\n",
        "# 하이퍼파라미터 정의 (어휘 크기, 임베딩 차원, LSTM 은닉 차원 및 출력 차원 설정)\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_DIM = 64\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 5\n",
        "\n",
        "# 모델 초기화 (LSTM 모델 인스턴스 생성)\n",
        "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의 (교차 엔트로피 손실과 SGD 사용)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# 모델 학습 과정 정의 (에포크 동안 훈련 데이터에 대해 손실 계산 및 가중치 업데이트)\n",
        "def train_model(model, train_dataloader, optimizer, criterion, epochs=10):\n",
        "    model.train()  # 모델을 학습 모드로 전환\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            reviews, ratings = batch  # 배치 데이터\n",
        "\n",
        "            # reviews와 ratings를 안전하게 복사\n",
        "            reviews = reviews.clone().detach()\n",
        "            ratings = ratings.clone().detach()\n",
        "\n",
        "            optimizer.zero_grad()  # 옵티마이저 초기화\n",
        "\n",
        "            # 모델의 출력\n",
        "            output = model(reviews)\n",
        "\n",
        "            # 손실 계산 및 역전파\n",
        "            loss = criterion(output, ratings)\n",
        "            loss.backward()  # 그라디언트 계산\n",
        "            optimizer.step()  # 옵티마이저를 통한 파라미터 업데이트\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "# 모델 학습 (훈련 함수 호출하여 모델 학습)\n",
        "train_model(model, train_dataloader, optimizer, criterion, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyP9iLcyAFCg",
        "outputId": "b2aefac6-8845-4c23-d064-e0d7712e694d"
      },
      "id": "eyP9iLcyAFCg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가 함수\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for reviews, labels in loader:\n",
        "            outputs = model(reviews)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# 모델 평가\n",
        "accuracy = evaluate(model, test_dataloader)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xaLjeYnAF3Z",
        "outputId": "d5af0c89-20d0-44ab-e2bb-ad6a49f5c6f9"
      },
      "id": "1xaLjeYnAF3Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import nltk\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 데이터 준비 (리뷰와 평점 컬럼을 추출)\n",
        "reviews = df['content']\n",
        "ratings = df['score']\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할 (train_test_split 사용)\n",
        "train_reviews, test_reviews, train_ratings, test_ratings = train_test_split(reviews, ratings, test_size=0.3, random_state=42)\n",
        "\n",
        "# 인덱스 초기화 (데이터 프레임 인덱스 리셋)\n",
        "train_reviews.reset_index(drop=True, inplace=True)\n",
        "train_ratings.reset_index(drop=True, inplace=True)\n",
        "test_reviews.reset_index(drop=True, inplace=True)\n",
        "test_ratings.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 단어 사전 구축 함수 정의 (리뷰 텍스트를 토큰화하고 사전 생성)\n",
        "def build_vocab(reviews):\n",
        "    tokenized_reviews = [word_tokenize(review) for review in reviews]\n",
        "    vocab = build_vocab_from_iterator(tokenized_reviews, specials=[\"<pad>\", \"<unk>\"])\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])  # 알 수 없는 단어 처리\n",
        "    return vocab\n",
        "\n",
        "# 데이터셋 클래스 정의 (데이터셋을 커스텀하여 사용하기 위해 클래스 정의)\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, reviews, ratings, text_pipeline, label_pipeline):\n",
        "        self.reviews = reviews\n",
        "        self.ratings = ratings\n",
        "        self.text_pipeline = text_pipeline\n",
        "        self.label_pipeline = label_pipeline\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        review = self.text_pipeline(self.reviews[idx])\n",
        "        rating = self.label_pipeline(self.ratings[idx])\n",
        "        return review, rating\n",
        "\n",
        "# 패딩과 텐서 변환을 위한 collate 함수 정의\n",
        "def collate_fn(batch):\n",
        "    reviews, ratings = zip(*batch)  # 배치에서 리뷰와 레이팅 분리\n",
        "    reviews_padded = pad_sequence(reviews, batch_first=True)  # 리뷰를 패딩\n",
        "    ratings_tensor = torch.tensor(ratings, dtype=torch.long)  # 레이팅을 텐서로 변환\n",
        "    return reviews_padded, ratings_tensor  # 패딩된 리뷰와 레이팅 반환\n",
        "\n",
        "# 단어 사전 생성 (훈련 데이터 리뷰를 기반으로 어휘 사전 구축)\n",
        "vocab = build_vocab(train_reviews)\n",
        "\n",
        "# 텍스트 파이프라인 정의 (텍스트를 토큰화하고 텐서로 변환)\n",
        "def text_pipeline(text):\n",
        "    tokenized = word_tokenize(text)  # 토큰화\n",
        "    return torch.tensor([vocab[token] for token in tokenized], dtype=torch.long)\n",
        "\n",
        "# 레이블 파이프라인 클래스 정의 (평점을 수치화하여 모델에 입력)\n",
        "class LabelPipeline:\n",
        "    def __init__(self):\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, labels):\n",
        "        self.label_encoder.fit(labels)\n",
        "\n",
        "    def __call__(self, label):\n",
        "        return self.label_encoder.transform([label])[0]\n",
        "\n",
        "# 레이블 파이프라인 초기화 및 학습\n",
        "label_pipeline = LabelPipeline()\n",
        "label_pipeline.fit(df['score'].values)\n",
        "\n",
        "# 데이터셋 정의 (훈련 및 테스트 데이터셋 구성)\n",
        "train_dataset = ReviewDataset(train_reviews, train_ratings, text_pipeline, label_pipeline)\n",
        "test_dataset = ReviewDataset(test_reviews, test_ratings, text_pipeline, label_pipeline)\n",
        "\n",
        "# 데이터 로더 정의 (DataLoader를 통해 배치로 데이터를 로딩)\n",
        "BATCH_SIZE = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "# 모델 정의 (LSTM 모델 구조를 설정하여 시퀀스 처리 수행)\n",
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=True, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Sequential(\n",
        "    nn.Linear(hidden_dim, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(128, output_dim)\n",
        ")\n",
        "\n",
        "  # 순전파 정의 (입력 텍스트를 임베딩하고 LSTM과 FC 계층에 통과)\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    output, (hidden, cell) = self.lstm(embedded)  # 배치 사이즈에 맞게 차원 추가\n",
        "    return self.fc(hidden[-1].view(hidden.size(1), -1))\n",
        "\n",
        "# 하이퍼파라미터 정의 (어휘 크기, 임베딩 차원, LSTM 은닉 차원 및 출력 차원 설정)\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_DIM = 64\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 5  # 예측할 점수 개수\n",
        "\n",
        "# 모델 초기화 (LSTM 모델 인스턴스 생성)\n",
        "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의 (교차 엔트로피 손실과 SGD 사용, 학습률 0.001로 설정)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# 모델 학습 과정 정의 (에포크 동안 훈련 데이터에 대해 손실 계산 및 가중치 업데이트)\n",
        "def train_model(model, train_dataloader, optimizer, criterion, epochs=10):\n",
        "    model.train()  # 모델을 학습 모드로 전환\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            reviews, ratings = batch  # 배치 데이터\n",
        "\n",
        "            # reviews와 ratings를 안전하게 복사\n",
        "            reviews = reviews.clone().detach()\n",
        "            ratings = ratings.clone().detach()\n",
        "\n",
        "            optimizer.zero_grad()  # 옵티마이저 초기화\n",
        "\n",
        "            # 모델의 출력\n",
        "            output = model(reviews)\n",
        "\n",
        "            # 손실 계산 및 역전파\n",
        "            loss = criterion(output, ratings)\n",
        "            loss.backward()  # 그라디언트 계산\n",
        "            optimizer.step()  # 옵티마이저를 통한 파라미터 업데이트\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "# 모델 학습 (훈련 함수 호출하여 모델 학습)\n",
        "train_model(model, train_dataloader, optimizer, criterion, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK5bbqPPJ-aV",
        "outputId": "9396611b-e776-49dd-fddc-05abb5a0e49d"
      },
      "id": "TK5bbqPPJ-aV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "accuracy = evaluate(model, test_dataloader)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btP1_07oKH6U",
        "outputId": "4d293faa-6964-42db-f623-e0ddef841a6c"
      },
      "id": "btP1_07oKH6U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [ 실험 결과 ]\n",
        "### [ 기본 : 간단한 LSTM 모델 (학습률 = 0.01) ]\n",
        "-> **정확도** = 0.6066\n",
        "### [ 기본 : 간단한 LSTM 모델 (학습률 = 0.001) ]\n",
        "-> **정확도** = 0.4573\n",
        "### [ 결론 ]\n",
        "-> 학습률을 0.01로 설정하는 것이 더 성능이 좋게 나옴"
      ],
      "metadata": {
        "id": "R3fDibVOX0hn"
      },
      "id": "R3fDibVOX0hn"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import nltk\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 데이터 준비 (리뷰와 평점 컬럼을 추출)\n",
        "reviews = df['content']\n",
        "ratings = df['score']\n",
        "\n",
        "# 훈련 및 테스트 데이터 분할 (train_test_split 사용)\n",
        "train_reviews, test_reviews, train_ratings, test_ratings = train_test_split(reviews, ratings, test_size=0.3, random_state=42)\n",
        "\n",
        "# 인덱스 초기화 (데이터 프레임 인덱스 리셋)\n",
        "train_reviews.reset_index(drop=True, inplace=True)\n",
        "train_ratings.reset_index(drop=True, inplace=True)\n",
        "test_reviews.reset_index(drop=True, inplace=True)\n",
        "test_ratings.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 단어 사전 구축 함수 정의 (리뷰 텍스트를 토큰화하고 사전 생성)\n",
        "def build_vocab(reviews):\n",
        "    tokenized_reviews = [word_tokenize(review) for review in reviews]\n",
        "    vocab = build_vocab_from_iterator(tokenized_reviews, specials=[\"<pad>\", \"<unk>\"])\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])  # 알 수 없는 단어 처리\n",
        "    return vocab\n",
        "\n",
        "# 데이터셋 클래스 정의 (데이터셋을 커스텀하여 사용하기 위해 클래스 정의)\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, reviews, ratings, text_pipeline, label_pipeline):\n",
        "        self.reviews = reviews\n",
        "        self.ratings = ratings\n",
        "        self.text_pipeline = text_pipeline\n",
        "        self.label_pipeline = label_pipeline\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        review = self.text_pipeline(self.reviews[idx])\n",
        "        rating = self.label_pipeline(self.ratings[idx])\n",
        "        return review, rating\n",
        "\n",
        "# 패딩과 텐서 변환을 위한 collate 함수 정의\n",
        "def collate_fn(batch):\n",
        "    reviews, ratings = zip(*batch)  # 배치에서 리뷰와 레이팅 분리\n",
        "    reviews_padded = pad_sequence(reviews, batch_first=True)  # 리뷰를 패딩\n",
        "    ratings_tensor = torch.tensor(ratings, dtype=torch.long)  # 레이팅을 텐서로 변환\n",
        "    return reviews_padded, ratings_tensor  # 패딩된 리뷰와 레이팅 반환\n",
        "\n",
        "# 단어 사전 생성 (훈련 데이터 리뷰를 기반으로 어휘 사전 구축)\n",
        "vocab = build_vocab(train_reviews)\n",
        "\n",
        "# 텍스트 파이프라인 정의 (텍스트를 토큰화하고 텐서로 변환)\n",
        "def text_pipeline(text):\n",
        "    tokenized = word_tokenize(text)  # 토큰화\n",
        "    return torch.tensor([vocab[token] for token in tokenized], dtype=torch.long)\n",
        "\n",
        "# 레이블 파이프라인 클래스 정의 (평점을 수치화하여 모델에 입력)\n",
        "class LabelPipeline:\n",
        "    def __init__(self):\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, labels):\n",
        "        self.label_encoder.fit(labels)\n",
        "\n",
        "    def __call__(self, label):\n",
        "        return self.label_encoder.transform([label])[0]\n",
        "\n",
        "# 레이블 파이프라인 초기화 및 학습\n",
        "label_pipeline = LabelPipeline()\n",
        "label_pipeline.fit(df['score'].values)\n",
        "\n",
        "# 데이터셋 정의 (훈련 및 테스트 데이터셋 구성)\n",
        "train_dataset = ReviewDataset(train_reviews, train_ratings, text_pipeline, label_pipeline)\n",
        "test_dataset = ReviewDataset(test_reviews, test_ratings, text_pipeline, label_pipeline)\n",
        "\n",
        "# 데이터 로더 정의 (DataLoader를 통해 배치로 데이터를 로딩)\n",
        "BATCH_SIZE = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "# 모델 정의 (LSTM 모델 구조를 설정하여 시퀀스 처리 수행)\n",
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Sequential(\n",
        "    nn.Linear(hidden_dim, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(128, output_dim)\n",
        ")\n",
        "\n",
        "  # 순전파 정의 (입력 텍스트를 임베딩하고 LSTM과 FC 계층에 통과)\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    output, (hidden, cell) = self.lstm(embedded)  # 배치 사이즈에 맞게 차원 추가\n",
        "    return self.fc(hidden[-1].view(hidden.size(1), -1))\n",
        "\n",
        "# 하이퍼파라미터 정의 (어휘 크기, 임베딩 차원, LSTM 은닉 차원 및 출력 차원 설정)\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_DIM = 64\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 5  # 예측할 점수 개수\n",
        "\n",
        "# 모델 초기화 (LSTM 모델 인스턴스 생성)\n",
        "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의 (교차 엔트로피 손실과 Adam 사용, 학습률 0.01로 설정)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 모델 학습 과정 정의 (에포크 동안 훈련 데이터에 대해 손실 계산 및 가중치 업데이트)\n",
        "def train_model(model, train_dataloader, optimizer, criterion, epochs=10):\n",
        "    model.train()  # 모델을 학습 모드로 전환\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            reviews, ratings = batch  # 배치 데이터\n",
        "\n",
        "            # reviews와 ratings를 안전하게 복사\n",
        "            reviews = reviews.clone().detach()\n",
        "            ratings = ratings.clone().detach()\n",
        "\n",
        "            optimizer.zero_grad()  # 옵티마이저 초기화\n",
        "\n",
        "            # 모델의 출력\n",
        "            output = model(reviews)\n",
        "\n",
        "            # 손실 계산 및 역전파\n",
        "            loss = criterion(output, ratings)\n",
        "            loss.backward()  # 그라디언트 계산\n",
        "            optimizer.step()  # 옵티마이저를 통한 파라미터 업데이트\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "# 모델 학습 (훈련 함수 호출하여 모델 학습)\n",
        "train_model(model, train_dataloader, optimizer, criterion, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlbVjnDV_6wu",
        "outputId": "2b848cef-396a-4d31-f525-248e2e223847"
      },
      "id": "mlbVjnDV_6wu",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "accuracy = evaluate(model, test_dataloader)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MmA0IjNAeZz",
        "outputId": "e286b1c8-cb98-4e04-fcbd-1c3ce909e2fe"
      },
      "id": "3MmA0IjNAeZz",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [ 실험 결과 ]\n",
        "### [ 기본 : 간단한 LSTM 모델 (SGD 옵티마이저)]\n",
        "-> **정확도** = 0.6066\n",
        "### [ Adam 옵티마이저 ]\n",
        "-> **정확도** = 0.6349\n",
        "### [ 결론 ]\n",
        "-> Adam 옵티마이저를 사용하는 것이 더 좋은 성능을 보임"
      ],
      "metadata": {
        "id": "P4QKx6mmR21S"
      },
      "id": "P4QKx6mmR21S"
    },
    {
      "cell_type": "code",
      "source": [
        "# 실험 3 : 조기종료 사용\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import nltk\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 데이터 준비 (리뷰와 평점 컬럼을 추출)\n",
        "reviews = df['content']\n",
        "ratings = df['score']\n",
        "\n",
        "# 데이터 분할\n",
        "# 훈련 데이터와 임시 데이터(검증 + 테스트 데이터) 분리(train_test_split 사용)\n",
        "train_reviews, temp_reviews, train_ratings, temp_ratings = train_test_split(reviews, ratings, test_size=0.3, random_state=42)\n",
        "\n",
        "# 임시 데이터를 검증 데이터와 테스트 데이터로 분리(train_test_split 사용)\n",
        "test_reviews, rtest_reviews, test_ratings, rtest_ratings = train_test_split(temp_reviews, temp_ratings, test_size=0.5, random_state=42)\n",
        "\n",
        "# 인덱스 초기화 (데이터 프레임 인덱스 리셋)\n",
        "train_reviews.reset_index(drop=True, inplace=True)\n",
        "train_ratings.reset_index(drop=True, inplace=True)\n",
        "test_reviews.reset_index(drop=True, inplace=True)\n",
        "test_ratings.reset_index(drop=True, inplace=True)\n",
        "rtest_reviews.reset_index(drop=True, inplace=True)\n",
        "rtest_ratings.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# 단어 사전 구축 함수 정의 (리뷰 텍스트를 토큰화하고 사전 생성)\n",
        "def build_vocab(reviews):\n",
        "    tokenized_reviews = [word_tokenize(review) for review in reviews]\n",
        "    vocab = build_vocab_from_iterator(tokenized_reviews, specials=[\"<pad>\", \"<unk>\"])\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])  # 알 수 없는 단어 처리\n",
        "    return vocab\n",
        "\n",
        "# 데이터셋 클래스 정의 (데이터셋을 커스텀하여 사용하기 위해 클래스 정의)\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, reviews, ratings, text_pipeline, label_pipeline):\n",
        "        self.reviews = reviews\n",
        "        self.ratings = ratings\n",
        "        self.text_pipeline = text_pipeline\n",
        "        self.label_pipeline = label_pipeline\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        review = self.text_pipeline(self.reviews[idx])\n",
        "        rating = self.label_pipeline(self.ratings[idx])\n",
        "        return review, rating  # tensor로 변환하지 않음\n",
        "\n",
        "# 패딩과 텐서 변환을 위한 collate 함수 정의\n",
        "def collate_fn(batch):\n",
        "    reviews, ratings = zip(*batch)  # 배치에서 리뷰와 레이팅 분리\n",
        "    reviews_padded = pad_sequence(reviews, batch_first=True)  # 리뷰를 패딩\n",
        "    ratings_tensor = torch.tensor(ratings, dtype=torch.long)  # 레이팅을 텐서로 변환\n",
        "    return reviews_padded, ratings_tensor  # 패딩된 리뷰와 레이팅 반환\n",
        "\n",
        "# 단어 사전 생성 (훈련 데이터 리뷰를 기반으로 어휘 사전 구축)\n",
        "vocab = build_vocab(train_reviews)\n",
        "\n",
        "# 텍스트 파이프라인 정의 (텍스트를 토큰화하고 텐서로 변환)\n",
        "def text_pipeline(text):\n",
        "    tokenized = word_tokenize(text)  # 토큰화\n",
        "    return torch.tensor([vocab[token] for token in tokenized], dtype=torch.long)  # 텐서를 LongTensor로 변환\n",
        "\n",
        "# 레이블 파이프라인 클래스 정의 (평점을 수치화하여 모델에 입력)\n",
        "class LabelPipeline:\n",
        "    def __init__(self):\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def fit(self, labels):\n",
        "        self.label_encoder.fit(labels)\n",
        "\n",
        "    def __call__(self, label):\n",
        "        return self.label_encoder.transform([label])[0]\n",
        "\n",
        "# 레이블 파이프라인 초기화 및 학습\n",
        "label_pipeline = LabelPipeline()\n",
        "label_pipeline.fit(df['score'].values)\n",
        "\n",
        "# 데이터셋 정의 (훈련 및 테스트 데이터셋 구성)\n",
        "train_dataset = ReviewDataset(train_reviews, train_ratings, text_pipeline, label_pipeline)\n",
        "test_dataset = ReviewDataset(test_reviews, test_ratings, text_pipeline, label_pipeline)\n",
        "rtest_dataset = ReviewDataset(rtest_reviews, rtest_ratings, text_pipeline, label_pipeline)\n",
        "\n",
        "# 데이터 로더 정의 (DataLoader를 통해 배치로 데이터를 로딩)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "rtest_dataloader = DataLoader(rtest_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "# 모델 정의 (LSTM 모델 구조를 설정하여 시퀀스 처리 수행)\n",
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "    self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Sequential(\n",
        "    nn.Linear(hidden_dim, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),  # 드롭아웃 추가\n",
        "    nn.Linear(128, output_dim)\n",
        ")\n",
        " # 순전파 정의 (입력 텍스트를 임베딩하고 LSTM과 FC 계층에 통과)\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    output, (hidden, cell) = self.lstm(embedded)  # 배치 사이즈에 맞게 차원 추가\n",
        "    return self.fc(hidden[-1].view(hidden.size(1), -1))  # hidden의 차원 변형\n",
        "\n",
        "# 하이퍼파라미터 정의 (어휘 크기, 임베딩 차원, LSTM 은닉 차원 및 출력 차원 설정)\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_DIM = 64\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = 5\n",
        "\n",
        "# 모델 초기화 (LSTM 모델 인스턴스 생성)\n",
        "model = LSTMModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "\n",
        "# 손실 함수와 옵티마이저 정의 (교차 엔트로피 손실과 Adam 사용, 학습률 0.01로 설정)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 조기 종료 함수 정의\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "        elif val_loss < self.best_loss:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                if self.verbose:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "\n",
        "# 모델 학습 과정 정의 (Early Stopping 추가)\n",
        "def train_model(model, train_dataloader, test_dataloader, optimizer, criterion, epochs=10, patience=1):\n",
        "    model.train()  # 모델을 학습 모드로 전환\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        # 훈련 모드에서의 손실 계산\n",
        "        for batch in train_dataloader:\n",
        "            reviews, ratings = batch  # 배치 데이터\n",
        "            optimizer.zero_grad()  # 옵티마이저 초기화\n",
        "\n",
        "            # 모델의 출력\n",
        "            output = model(reviews)\n",
        "\n",
        "            # 손실 계산 및 역전파\n",
        "            loss = criterion(output, ratings)\n",
        "            loss.backward()  # 그라디언트 계산\n",
        "            optimizer.step()  # 옵티마이저를 통한 파라미터 업데이트\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "        # 테스트 손실 계산\n",
        "        model.eval()  # 모델을 평가 모드로 전환\n",
        "        total_test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_dataloader:\n",
        "                reviews, ratings = batch  # 배치 데이터\n",
        "                output = model(reviews)  # 모델의 출력\n",
        "                test_loss = criterion(output, ratings)  # 테스트 손실 계산\n",
        "                total_test_loss += test_loss.item()\n",
        "\n",
        "        avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Test Loss: {avg_test_loss:.4f}')\n",
        "\n",
        "        # Early Stopping 체크\n",
        "        if early_stopping(avg_test_loss):\n",
        "            break  # 학습 중단\n",
        "\n",
        "# 모델 학습 (훈련 함수 호출하여 모델 학습)\n",
        "train_model(model, train_dataloader, test_dataloader, optimizer, criterion, epochs=10, patience=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt3TIJ_8dcEl",
        "outputId": "1735a1a1-f48c-4a10-d01a-e27b165e3a56"
      },
      "id": "Mt3TIJ_8dcEl",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 1.0814\n",
            "Epoch [1/10], Test Loss: 0.9967\n",
            "Epoch [2/10], Train Loss: 0.9420\n",
            "Epoch [2/10], Test Loss: 0.9797\n",
            "Epoch [3/10], Train Loss: 0.8920\n",
            "Epoch [3/10], Test Loss: 1.0064\n",
            "Epoch [4/10], Train Loss: 0.8613\n",
            "Epoch [4/10], Test Loss: 1.0024\n",
            "Epoch [5/10], Train Loss: 0.8284\n",
            "Epoch [5/10], Test Loss: 1.0070\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "accuracy = evaluate(model, rtest_dataloader)\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKiT8rZseORi",
        "outputId": "bcdd6995-9e28-449d-872a-3b7ba861fbc5"
      },
      "id": "wKiT8rZseORi",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [ 실험 결과 ]\n",
        "### [ Adam 옵티마이저 ]\n",
        "-> **정확도** = 0.6349\n",
        "### [ 조기종료 사용 ]\n",
        "-> **정확도** = 0.6356\n",
        "### [ 결론 ]\n",
        "-> 조기종료를 사용해도 성능의 차이는 크지 않지만 모델 학습시키는 시간이 훨씬 단축됨"
      ],
      "metadata": {
        "id": "u_bGgsIQycHi"
      },
      "id": "u_bGgsIQycHi"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (ml_test)",
      "language": "python",
      "name": "ml_test"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}