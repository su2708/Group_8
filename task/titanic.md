### íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡

<aside>
ğŸ’¡ **ì£¼ì œ**

íƒ€ì´íƒ€ë‹‰ íƒ‘ìŠ¹ê° ë°ì´í„°ì…‹ì„ í™œìš©í•´ ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ ë§Œë“œëŠ” í”„ë¡œì íŠ¸

</aside>

<aside>
ğŸ¯ **ëª©í‘œ**
ë‹¤ì–‘í•œ ëª¨ë¸ì„ í†µí•´ì„œ ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. 
ê³¼ì œëŠ” ìˆœì„œëŒ€ë¡œ í’€ì–´ì£¼ì„¸ìš”.

</aside>

### **í•„ìˆ˜ ê³¼ì œ:**

1. **ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°** 
    
    `seaborn` ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ìˆëŠ” titanic ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    
    - ì°¸ê³ 
        
        ```jsx
        import seaborn as sns
        
        titanic = sns.load_dataset('titanic')
        ```
        
2. **feature ë¶„ì„**
    
    ë°ì´í„°ë¥¼ ì˜ ë¶ˆëŸ¬ì˜¤ì…¨ë‹¤ë©´ í•´ë‹¹ ë°ì´í„°ì˜ featureë¥¼ íŒŒì•…í•´ì•¼í•©ë‹ˆë‹¤. ë°ì´í„°ì˜ featureë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ ì•„ë˜ì˜ ë‹¤ì–‘í•œ feature ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”. 
    
    2-1. `head` í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë°ì´í„° í”„ë ˆì„ì˜ ì²« 5í–‰ì„ ì¶œë ¥í•˜ì—¬ ì–´ë–¤ featureë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. 
    
    - ì°¸ê³ 
        
        ```jsx
        titanic.head()
        ```
        
    
     2-2. `describe` í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ê¸°ë³¸ì ì¸ í†µê³„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. 
    
    - ì°¸ê³ 
        
        ```jsx
        titanic.describe()
        ```
        
    
    2-3. `describe` í•¨ìˆ˜ë¥¼ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆëŠ” `count`, `std`, `min`, `25%`, `50%`, `70%`, `max` ê°€ ê°ê° ë¬´ìŠ¨ ëœ»ì¸ì§€ ì£¼ì„ í˜¹ì€ markdown ë¸”ë¡ìœ¼ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”. 
    
    - ì°¸ê³ 
        
        ```python
        # count: countëŠ” ã…‡ã…‡ã…‡í•œ ê°’ìœ¼ë¡œ ã…‡ã…‡ã…‡ã…‡í•¨ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ã…‡ã…‡ã…‡ì„ í†µí•´ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # std: ...
        ```
        
    
    2-4. `isnull()` í•¨ìˆ˜ì™€ `sum()`  í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ê° ì—´ì˜ ê²°ì¸¡ì¹˜ ê°¯ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.
    
    - ì°¸ê³ 
        
        ```python
        print(titanic.isnull().sum())
        ```
        
3. **feature engineering**
    
    feature engineeringì€ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì¤‘ìš”í•œ ë‹¨ê³„ì…ë‹ˆë‹¤. 2ë²ˆ feature ë¶„ì„ì—ì„œ ì–»ì€ ë°ì´í„°ì— ëŒ€í•œ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ì˜ feature engineeringì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”. 
    
    **3-1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬**
    
    Age(ë‚˜ì´)ì˜ ê²°ì¸¡ì¹˜ëŠ” ì¤‘ì•™ê°’ìœ¼ë¡œ, Embarked(ìŠ¹ì„  í•­êµ¬)ì˜ ê²°ì¸¡ì¹˜ëŠ” ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´í•´ì£¼ì„¸ìš”. ëª¨ë‘ ëŒ€ì²´í•œ í›„ì—, ëŒ€ì²´ ê²°ê³¼ë¥¼ `isnull()` í•¨ìˆ˜ì™€ `sum()`  í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ í™•ì¸í•´ì£¼ì„¸ìš”. 
    
    - ì°¸ê³ 
        
        ```python
        titanic['age'].fillna(titanic['age'].median(), inplace=True)
        titanic['embarked'].fillna(titanic['embarked'].mode()[0], inplace=True)
        
        print(titanic['age'].isnull().sum())
        print(titanic['embarked'].isnull().sum())
        ```
        
    
    **3-2. ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ì¸ì½”ë”©**
    
    Sex(ì„±ë³„)ë¥¼ ë‚¨ìëŠ” 0, ì—¬ìëŠ” 1ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. alive(ìƒì¡´ì—¬ë¶€)ë¥¼ TrueëŠ” 1, FalseëŠ” 0ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. Embarked(ìŠ¹ì„  í•­êµ¬)ëŠ” â€˜Câ€™ëŠ” 0ìœ¼ë¡œ, QëŠ” 1ìœ¼ë¡œ, â€˜Sâ€™ëŠ” 2ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”. ëª¨ë‘ ë³€í™˜í•œ í›„ì—, ë³€í™˜ ê²°ê³¼ë¥¼ `head` í•¨ìˆ˜ë¥¼ ì´ìš©í•´ í™•ì¸í•´ì£¼ì„¸ìš”. 
    
    - ì°¸ê³ 
        
        ```python
        titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})
        titanic['alive'] = titanic['alive'].map({'no': 1, 'yes': 0})
        titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2,})
        
        print(titanic['sex'].head())
        print(titanic['alive'].head())
        print(titanic['embarked'].head())
        ```
        
    
    **3-3. ìƒˆë¡œìš´ feature ìƒì„±**
    
    SibSip(íƒ€ì´íƒ€ë‹‰í˜¸ì— ë™ìŠ¹í•œ ìë§¤ ë° ë°°ìš°ìì˜ ìˆ˜), Parch(íƒ€ì´íƒ€ë‹‰í˜¸ì— ë™ìŠ¹í•œ ë¶€ëª¨ ë° ìì‹ì˜ ìˆ˜)ë¥¼ í†µí•´ì„œ family_size(ê°€ì¡±í¬ê¸°)ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. ìƒˆë¡œìš´ featureë¥¼ `head` í•¨ìˆ˜ë¥¼ ì´ìš©í•´ í™•ì¸í•´ì£¼ì„¸ìš”. 
    
    - ì°¸ê³ 
        
        ```python
        titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1
        
        print(titanic['family_size'].head())
        ```
        
4. **ëª¨ë¸ í•™ìŠµì‹œí‚¤ê¸° (Logistic Regression, Random Forest, XGBoost)**
    
    4-1. ëª¨ë¸ í•™ìŠµ ì¤€ë¹„ 
    
    ì´ì œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ê² ìŠµë‹ˆë‹¤. í•™ìŠµì— í•„ìš”í•œ featureì€ 'survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', â€˜family_sizeâ€™ ì…ë‹ˆë‹¤. featureê³¼ targetì„ ë¶„ë¦¬í•´ì£¼ì„¸ìš”.  ê·¸ ë‹¤ìŒ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ì„ ì§„í–‰í•´ì£¼ì„¸ìš”. 
    
    - ì°¸ê³ 
        
        ```python
        titanic = titanic[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'family_size']]
        X = titanic.drop('survived', axis=1) # feature
        y = titanic['survived'] # target
        ```
        
    
    ì´ì œ Logistic Regression, Random Forest, XGBoostë¥¼ í†µí•´ì„œ ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”. í•™ìŠµì´ ëë‚œ ë’¤ Logistic Regressionê³¼ Random ForestëŠ” ëª¨ë¸ accuracyë¥¼ í†µí•´, XGBoostëŠ” mean squared errorë¥¼ í†µí•´ test dataë¥¼ ì˜ˆì¸¡í•˜ì„¸ìš”. 
    
    4-2. Logistic Regression
    
    - ì°¸ê³ 
        
        ```python
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)
        
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        model = LogisticRegression()
        model.fit(X_train, y_train)
        
        # ì˜ˆì¸¡
        y_pred = model.predict(X_test)
        
        # í‰ê°€
        print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
        print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
        ```
        
    
    4-3. Random Forest
    
    - ì°¸ê³ 
        
        ```python
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)
        X_test = scaler.transform(X_test)
        
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        model = DecisionTreeClassifier(random_state=42)
        model.fit(X_train, y_train)
        
        # ì˜ˆì¸¡
        y_pred = model.predict(X_test)
        
        # í‰ê°€
        print(f"Accuracy: {accuracy_score(y_test, y_pred)}")
        print(f"Classification Report:\n{classification_report(y_test, y_pred)}")
        ```
        
    
    4-4. XGBoost
    
    - ì°¸ê³ 